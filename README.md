# ğŸ¤ 30 Days of Voice Agents â€” Conversational Echo Bot

A real-time **voice agent** built with **Flask**, **AssemblyAI Speech-to-Text**, **Google Gemini LLM**, and **Murf.ai Text-to-Speech**.  
This bot listens to your voice, transcribes it, processes your request with an LLM, and responds back with generated human-like speech â€” preserving conversation history.

---

## ğŸ“Œ Features

- **Speech-to-Text (STT)** with [AssemblyAI](https://www.assemblyai.com/)  
- **Conversational AI** with [Google Gemini](https://ai.google/google-gemini/)  
- **Text-to-Speech (TTS)** with [Murf.ai](https://murf.ai/)  
- **Persistent Conversation History** in memory (per `session_id`)  
- Interactive **web interface** with start/stop recording controls  
- **Fallback handling** if any API call fails (returns default audio + message)  
- Automatic text shortening for TTS if over character limit  
- Simple **REST API** to use from other clients

---

## ğŸ› ï¸ Tech Stack

**Backend:**
- Python 3.x
- Flask
- Requests
- AssemblyAI Python SDK (`assemblyai`)
- Google Generative AI SDK (`google-generativeai`)
- Python-dotenv

**Frontend:**
- HTML / CSS / JavaScript
- Native MediaRecorder API for recording
- Fetch API for communication

---

## ğŸ—ï¸ Architecture
    ğŸ¤ User Speaks
            â†“ 
    (Browser Microphone)[ MediaRecorder API in Browser ]
            â†“
    ğŸ§ Audio sent to Flask /agent/chat/<session_id>
            â†“
    (1) ğŸ“œ STT via AssemblyAI â†’ Transcript
    (2) ğŸ¤– Gemini LLM â†’ Generates AI Response
    (3) ğŸ”Š Murf TTS â†’ Converts Response to Speech
            â†“
    ğŸ“¦ Flask stores and serves audio from /static
            â†“
    ğŸ” Browser plays AI voice + updates conversation view


---

## ğŸ“‚ Project Structure

    voice_agent_app/
    â”‚
    â”œâ”€â”€ app.py                  # Flask app entry
    â”œâ”€â”€ config.py               # API keys, folder paths
    â”œâ”€â”€ schemas/                # Pydantic request/response models
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ llm.py
    â”‚   â”œâ”€â”€ tts.py
    â”‚   â”œâ”€â”€ stt.py
    â”‚   â”œâ”€â”€ agent.py
    â”‚
    â”œâ”€â”€ services/               # Wrappers for 3rd party APIs
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ llm_service.py
    â”‚   â”œâ”€â”€ stt_service.py
    â”‚   â”œâ”€â”€ tts_service.py
    â”‚
    â”œâ”€â”€ utils/                  
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ logger.py           # Logging setup
    â”‚
    â”œâ”€â”€ static/
    â”œâ”€â”€ templates/
    â””â”€â”€ requirements.txt


---

## ğŸ”‘ Environment Variables

    Create a `.env` file in the project root:
        ASSEMBLYAI_API_KEY=your_assemblyai_api_key
        MURF_API_KEY=your_murf_api_key
        GEMINI_API_KEY=your_gemini_api_key


Make sure you have valid API keys for all three services.

---

## ğŸš€ Running Locally

    1ï¸âƒ£ **Clone the repository**
        git clone https://github.com/yourusername/voice-agent.git
        cd voice-agent


    2ï¸âƒ£ **Create and activate a virtual environment**
        python -m venv venv
        source venv/bin/activate # On macOS/Linux
        venv\Scripts\activate # On Windows


    3ï¸âƒ£ **Install dependencies**
        pip install -r requirements.txt


    4ï¸âƒ£ **Set environment variables**
        cp .env.example .env

        Fill in your API keys inside .env


    5ï¸âƒ£ **Run the Flask server**
        python app.py


---

## ğŸ“¡ API Endpoints

### **1. Transcribe Only**
    `POST /tts/echo`
        - **Form-Data**: `audio` (Uploaded audio file)
        - **Response**:
            {
            "transcript": "Hello world"
            }

---

    ### **2. LLM Query**
        `POST /llm/query`
        - **JSON body**:
            {
            "text": "Write a haiku about the ocean"
            }

        - **Response**:
            {
            "response": "Calm waves drift ashore..."
            }


    ---

    ### **3. Generate TTS from Transcript**
        `POST /generate-murf-from-transcript`
        - **JSON body**:
            {
            "transcript": "Your AI generated text here..."
            }

        - **Response**:
            {
            "audio_url": "/static/murf_xxx.mp3"
            }
        

    ---

    ### **4. Conversational Agent**
        `POST /agent/chat/<session_id>`
        - **Form-Data**: `audio` (User's voice)
        - **Response**:
        {
        "session_id": "s_1720000000000",
        "transcript": "User text",
        "response_text": "Bot reply",
        "audio_url": "/static/murf_s_1720000000000.mp3"
        }



