# ğŸ¤ 30 Days of Voice Agents â€” Conversational Echo Bot

A real-time **voice agent** built with **Flask**, **AssemblyAI Speech-to-Text**, **Google Gemini LLM**, and **Murf.ai Text-to-Speech**.  
This bot listens to your voice, transcribes it, processes your request with an LLM, and responds back with generated human-like speech â€” preserving conversation history.

---

## ğŸ“Œ Features

- **Speech-to-Text (STT)** with [AssemblyAI](https://www.assemblyai.com/)  
- **Conversational AI** with [Google Gemini](https://ai.google/google-gemini/)  
- **Text-to-Speech (TTS)** with [Murf.ai](https://murf.ai/)  
- **Persistent Conversation History** in memory (per `session_id`)  
- Interactive **web interface** with start/stop recording controls  
- **Fallback handling** if any API call fails (returns default audio + message)  
- Automatic text shortening for TTS if over character limit  
- Simple **REST API** to use from other clients

---

## ğŸ› ï¸ Tech Stack

**Backend:**
- Python 3.x
- Flask
- Requests
- AssemblyAI Python SDK (`assemblyai`)
- Google Generative AI SDK (`google-generativeai`)
- Python-dotenv

**Frontend:**
- HTML / CSS / JavaScript
- Native MediaRecorder API for recording
- Fetch API for communication

---

## ğŸ—ï¸ Architecture
   flowchart TD
  %% Sections
  subgraph Client[Client (Browser)]
    Mic[ğŸ¤ Record audio (MediaRecorder)]
    UI[ğŸ–¥ï¸ Conversation UI]
  end

  subgraph Server[Flask Server]
    Route[/POST /agent/chat/<session_id>/]
    Store[ğŸ“¦ Save MP3 to /static]
    Hist[ğŸ—‚ï¸ Inâ€‘memory chat history]
  end

  subgraph Services[Service Layer]
    STT[ğŸ“œ STT: AssemblyAI]
    LLM[ğŸ¤– LLM: Gemini]
    TTS[ğŸ”Š TTS: Murf]
  end

  %% Flow
  Mic -->|audio/webm| Route
  UI -->|Start/Stop| Mic

  %% (1) STT
  Route -->|1) Transcribe| STT
  STT -->|Transcript| Route

  %% (2) LLM
  Route -->|2) Prompt + History| LLM
  LLM -->|AI Response Text| Route
  Route --> Hist

  %% (3) TTS
  Route -->|3) Synthesize| TTS
  TTS -->|MP3 bytes| Store
  Store -->|/static/<file>.mp3| UI

  %% Playback + UI update
  UI -->|Play AI voice| UI
  UI -->|Update chat view| UI



---

## ğŸ“‚ Project Structure

project/
â”‚
â”œâ”€â”€ app.py # Flask backend
â”œâ”€â”€ templates/
â”‚ â””â”€â”€ index.html # Web interface
â”œâ”€â”€ static/
â”‚ â”œâ”€â”€ script.js # Client-side JS logic
â”‚ â”œâ”€â”€ style.css # UI styles
â”‚ â””â”€â”€ fallback.mp3 # Optional fallback audio
â”œâ”€â”€ uploads/ # Temp uploaded audio files
â”œâ”€â”€ .env # API keys (not tracked in git)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md # You are here

---

## ğŸ”‘ Environment Variables

Create a `.env` file in the project root:
    ASSEMBLYAI_API_KEY=your_assemblyai_api_key
    MURF_API_KEY=your_murf_api_key
    GEMINI_API_KEY=your_gemini_api_key


Make sure you have valid API keys for all three services.

---

## ğŸš€ Running Locally

1ï¸âƒ£ **Clone the repository**
git clone https://github.com/yourusername/voice-agent.git
cd voice-agent


2ï¸âƒ£ **Create and activate a virtual environment**
python -m venv venv
source venv/bin/activate # On macOS/Linux
venv\Scripts\activate # On Windows


3ï¸âƒ£ **Install dependencies**
pip install -r requirements.txt


4ï¸âƒ£ **Set environment variables**
cp .env.example .env

Fill in your API keys inside .env


5ï¸âƒ£ **Run the Flask server**
python app.py


---

## ğŸ“¡ API Endpoints

### **1. Transcribe Only**
`POST /tts/echo`
- **Form-Data**: `audio` (Uploaded audio file)
- **Response**:
    {
    "transcript": "Hello world"
    }

---

### **2. LLM Query**
`POST /llm/query`
- **JSON body**:
    {
    "text": "Write a haiku about the ocean"
    }

- **Response**:
    {
    "response": "Calm waves drift ashore..."
    }


---

### **3. Generate TTS from Transcript**
`POST /generate-murf-from-transcript`
- **JSON body**:
    {
    "transcript": "Your AI generated text here..."
    }

- **Response**:
    {
    "audio_url": "/static/murf_xxx.mp3"
    }
    

---

### **4. Conversational Agent**
`POST /agent/chat/<session_id>`
- **Form-Data**: `audio` (User's voice)
- **Response**:
{
"session_id": "s_1720000000000",
"transcript": "User text",
"response_text": "Bot reply",
"audio_url": "/static/murf_s_1720000000000.mp3"
}




